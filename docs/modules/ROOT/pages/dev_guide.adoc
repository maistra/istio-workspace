:cmd-changelog: /changelog
:cmd-release: /release
:cmd-shipit: /shipit
:sample-version: v0.1.0 
:initial-commit: release: highlights of {sample-version}
:base-branch: master
:pr-url: https://github.com/maistra/istio-workspace/pull/800

= Development Guide

== Local Development

=== Using Minikube

For installation guide please refer to https://minikube.sigs.k8s.io/docs/start/[official minikube documentation]. 

TIP: It's recommended to use rather generous memory settings to avoid unnecessary hiccups of the platform. For example `minikube start --cpus=4 --memory=16g` should be sufficient for most of the cases.

==== Additional configuration steps

. Installing Istio
+
By simply using `istioctl install` you can roll out default istio deployment which is sufficient for development practices. Check how to install `istioctl` command line tool on your OS in the https://istio.io/latest/docs/setup/install/istioctl/[official docs].

. Installing Operator Lifecycle Management in the cluster
+
[source,shell,indent=0]
----
include::example$config.yml[tag=olm]
----

. Enabling the tunnel
+
For ease of use you could also enable the tunneling. This will create a route to services deployed with type LoadBalancer and sets their Ingress to their ClusterIP. Simply invoke `minikube tunnel` in another terminal window (or run it in the background).

==== Running end-to-end tests

To run the tests against local `minikube` instance you have to set few environment variables which you can pass as `ENV_FILE` and execute:

First, create `minikube.env`. As each time some variables can differ (such as IP of the cluster), it's good to have them evaluated on the fly. You can use following snippet to create `.env` file.

[source,bash]
.minikube.env
----
cat <<EOF > minikubea.env                                         
IKE_E2E_MANAGE_CLUSTER=false
ISTIO_NS=istio-system
IKE_IMAGE_TAG=latest
TELEPRESENCE_VERSION=0.109
IKE_CLUSTER_HOST=$(minikube ip)
IKE_ISTIO_INGRESS=http://$(k get svc istio-ingressgateway -n istio-system -o jsonpath='{.spec.clusterIP}')/
IKE_INTERNAL_CONTAINER_REGISTRY=quay.io
IKE_EXTERNAL_CONTAINER_REGISTRY=quay.io
IKE_CONTAINER_REPOSITORY=maistra-dev
PRE_BUILT_IMAGES=true
EOF
----

IMPORTANT: Setting `PRE_BUILT_IMAGES=true` will result in pulling required images from `quay.io/maistra-dev`. If you would like to use internal/local registry refer to <<microk8s-e2e,microk8s e2e tests example>>.

With the created `.env` file you can now launch end-to-end tests passing following variable:

[source,bash]
----
ENV_FILE=minikube.env make test-e2e
----

=== Using MicroK8s

MicroK8s is a lightweight, upstream Kubernetes distribution which you can run on your machine to develop and test changes. 

Check https://microk8s.io/docs[official docs] to see how you can install it on your OS.


==== Needed customizations

. Enable following services:
+
[source,bash]
----
microk8s.enable dns registry istio 
----

. Point `kubectl` to `microk8s` instance, for example:
+
[source,bash]
----
sudo microk8s.kubectl config view --raw > /tmp/kubeconfig
export KUBECONFIG=/tmp/kubeconfig
----

[NOTE]
You might end up with Istio unable reach outside networks. 
See this https://github.com/ubuntu/microk8s/issues/316[thread] and the solution specific for https://github.com/ubuntu/microk8s/issues/408[Fedora].

[#microk8s-e2e]
==== Running end-to-end tests

To run the tests against local `microk8s` instance you have to set few environment variables which you can pass as `ENV_FILE` and execute:

[source,bash]
----
ENV_FILE=microk8s.env make test-e2e
----

[source,.env]
.microk8s.env
----
IKE_E2E_MANAGE_CLUSTER=false
ISTIO_NS=istio-system
IKE_IMAGE_TAG=latest
TELEPRESENCE_VERSION=0.105
IKE_CLUSTER_HOST=localhost
IKE_ISTIO_INGRESS=http://localhost:31380
IKE_INTERNAL_CONTAINER_REGISTRY=localhost:32000
IKE_EXTERNAL_CONTAINER_REGISTRY=localhost:32000
----

IMPORTANT: In this case executing `make test-e2e` will result in building all the required images and pushing them to internal registry (see values of `IKE_INTERNAL_CONTAINER_REGISTRY` and `IKE_EXTERNAL_CONTAINER_REGISTRY`).  

== Release

== Release automation driven by Pull Request

By creating a Pull Request with release notes, we can automate the release process simply by using commands in the comments.
You can see actual example {pr-url}[here]. 

=== Creating release branch

Running `make draft-release-notes VERSION={sample-version}` creates new release notes file and initial commit titled `{initial-commit}`. This commit will also become a title of the Pull Request. If there are noteworthy highlights you can write a few paragraphs in the created file `docs/modules/ROOT/pages/release_notes/{sample-version}.adoc`.

=== Changelog generation using `{cmd-changelog}` command

An owner, committer, or a member of our organization can use `{cmd-changelog}` command to trigger changelog generation for the `{sample-version}` version (which is inferred from PR title).

Such a comment results in adding commits to created PR which consists of:

* changelog based on all PRs since the last release, which will be appended to release highlights submitted as part of this PR.

Changelog generation job performs validation and will fail if one of the issues listed below occurs:

* `version` in the title does not conform with https://semver.org/[semantic versioning]
* `version` has been already released
* release notes do not exist (submitting this file is the only thing needed for this {pr-url}[PR])
* any of the PRs created since the last release have no labels and thus cannot be categorized by

In all the cases above PR will have `release / changelog` status set to failure and comment with an appropriate error message will be added
by the bot. You can see that in the {pr-url}[comments of the sample PR].

=== Preparing the release using `{cmd-release}` command

This command will squash all previous commits to `{initial-commit}` for streamlined history.

Next it will create the following commits:

* "version commit" (e.g. `release: {sample-version}`) which consist of documentation version lock to `{sample-version}` and special `/tag` directive in the message. 
This directive later used to create actual tag when PR is rebased onto `{base-branch}` branch.
* commit which reverts documentation version lock back to `latest`.


=== Triggering release process by invoking `{cmd-shipit}`

Once both steps above succeeds, we can trigger the actual release process. This can be done by commenting with `{cmd-shipit}`.

This will result in rebasing this PR on top of the target branch if all the required checks have been successful. Once "release commit" appears
on the target branch it will be automatically tagged based on `/tag VERSION` comment in its message. That tag will trigger the
actual release process which consists of:

. building and pushing tagged container images to `quay.io` registry
. opening Pull Request with new operator version in Operator Hub
. opening Pull Request with new version of Tekton tasks.
. pushing cross-compiled binaries and release notes to GitHub
. generating documentation for released version

Diagram below describes the entire process and its artifacts.

.Release automation
image::diagrams/release-automation.svg[Release automation]
// Source: https://drive.google.com/file/d/1m0r9AH3LntqgZ5K_IuF6KVcz5QGF2XhX/view?usp=sharing through draw.io
